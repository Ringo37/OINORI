<!DOCTYPE html>
<html>
  <head>
    <title>Realtime Transcription & Visualizer</title>
    <style>
      /* 全体のレイアウト設定 */
      body {
        margin: 0;
        padding: 0;
        width: 100vw;
        height: 100vh;
        background-color: #1a1a1a; /* 暗い背景 */
        display: flex;
        justify-content: center;
        align-items: center;
        overflow: hidden;
        font-family: sans-serif;
      }

      /* 操作ボタンのコンテナ（左上に配置） */
      .controls {
        position: absolute;
        top: 20px;
        left: 20px;
        z-index: 100;
        background: rgba(0, 0, 0, 0.5);
        padding: 10px;
        border-radius: 8px;
      }

      button {
        padding: 8px 16px;
        cursor: pointer;
        font-size: 14px;
      }

      /* 音に反応する球体 */
      #sphere {
        width: 150px;
        height: 150px;
        background: linear-gradient(135deg, #00d2ff 0%, #3a7bd5 100%);
        border-radius: 50%;
        box-shadow: 0 0 30px rgba(0, 210, 255, 0.6);
        transition: transform 0.05s ease-out; /* 滑らかに動かす */
        will-change: transform;
      }

      /* 字幕エリア全体 */
      #transcription {
        position: absolute;
        bottom: 10%;
        width: 80%;
        text-align: center;
        font-size: 1.5rem; /* 少し小さくして複数行見やすく */
        font-weight: bold;
        text-shadow: 2px 2px 4px #000000, 0 0 10px rgba(0, 0, 0, 0.8);
        pointer-events: none;
        line-height: 1.5;
        max-height: 40vh; /* 表示エリアを広げる */
        overflow: hidden;
        display: flex;
        flex-direction: column;
        justify-content: flex-end;
        align-items: center;
      }

      /* 個別のメッセージスタイル */
      .message-row {
        margin: 5px 0;
        padding: 5px 15px;
        border-radius: 10px;
        animation: fadeIn 0.3s ease-in;
      }

      /* ユーザーの発言（白） */
      .user-message {
        color: #ffffff;
      }

      /* AIの発言（黄色・少し強調） */
      .ai-message {
        color: #ffeb3b; /* 鮮やかな黄色 */
        font-size: 1.1em; /* 少し大きく */
      }

      /* エラーメッセージ（赤） */
      .error-message {
        color: #ff5252;
      }

      @keyframes fadeIn {
        from {
          opacity: 0;
          transform: translateY(10px);
        }
        to {
          opacity: 1;
          transform: translateY(0);
        }
      }
    </style>
  </head>
  <body>
    <div class="controls">
      <h1 style="color: white; font-size: 16px; margin: 0 0 10px 0">
        AI Conversation
      </h1>
      <button id="startBtn">Start Recording</button>
      <button id="stopBtn" disabled>Stop</button>
    </div>

    <div id="sphere"></div>

    <div id="transcription"></div>

    <script>
      let socket;
      let audioContext;
      let processor;
      let input;
      let globalStream;
      let analyser;
      let animationId;

      const startBtn = document.getElementById("startBtn");
      const stopBtn = document.getElementById("stopBtn");
      const transcriptionDiv = document.getElementById("transcription");
      const sphere = document.getElementById("sphere");

      startBtn.onclick = async () => {
        // WebSocket接続
        socket = new WebSocket(
          "ws://" + window.location.host + "/ws/transcribe/"
        );

        socket.onopen = async () => {
          console.log("WebSocket Connected");
          startRecording();
        };

        socket.onmessage = (e) => {
          const data = JSON.parse(e.data);

          // --- 音声データの受信処理 (追加) ---
          if (data.type === "audio") {
            // Base64文字列から音声を再生
            const audio = new Audio("data:audio/mp3;base64," + data.audio);
            audio.play().catch((e) => console.error("再生エラー:", e));
            return; // 音声のみの場合はここで終了
          }
          // ------------------------------

          const div = document.createElement("div");
          div.classList.add("message-row");
          div.innerText = data.message;

          if (data.type === "ai") {
            div.classList.add("ai-message");
          } else if (data.type === "error") {
            div.classList.add("error-message");
          } else {
            div.classList.add("user-message");
          }

          transcriptionDiv.appendChild(div);

          if (transcriptionDiv.childElementCount > 6) {
            transcriptionDiv.removeChild(transcriptionDiv.firstChild);
          }
        };
      };

      stopBtn.onclick = () => {
        stopRecording();
        if (socket) socket.close();
      };

      async function startRecording() {
        startBtn.disabled = true;
        stopBtn.disabled = false;
        transcriptionDiv.innerHTML = "";

        audioContext = new (window.AudioContext || window.webkitAudioContext)({
          sampleRate: 16000,
        });

        try {
          globalStream = await navigator.mediaDevices.getUserMedia({
            audio: true,
          });
          input = audioContext.createMediaStreamSource(globalStream);

          analyser = audioContext.createAnalyser();
          analyser.fftSize = 256;
          input.connect(analyser);

          visualize();

          processor = audioContext.createScriptProcessor(4096, 1, 1);
          input.connect(processor);

          const muteNode = audioContext.createGain();
          muteNode.gain.value = 0;
          processor.connect(muteNode);
          muteNode.connect(audioContext.destination);

          processor.onaudioprocess = (e) => {
            const inputData = e.inputBuffer.getChannelData(0);
            if (socket && socket.readyState === WebSocket.OPEN) {
              socket.send(inputData.buffer);
            }
          };
        } catch (e) {
          console.error(e);
          alert("マイクへのアクセスが拒否されました");
        }
      }

      function visualize() {
        if (!analyser) return;

        const dataArray = new Uint8Array(analyser.frequencyBinCount);
        analyser.getByteFrequencyData(dataArray);

        let sum = 0;
        for (let i = 0; i < dataArray.length; i++) {
          sum += dataArray[i];
        }
        const average = sum / dataArray.length;

        const scale = 1 + average * 0.02;

        sphere.style.transform = `scale(${scale})`;

        animationId = requestAnimationFrame(visualize);
      }

      function stopRecording() {
        startBtn.disabled = false;
        stopBtn.disabled = true;

        if (globalStream)
          globalStream.getTracks().forEach((track) => track.stop());
        if (processor) processor.disconnect();
        if (analyser) analyser.disconnect();
        if (input) input.disconnect();
        if (audioContext) audioContext.close();
        if (animationId) cancelAnimationFrame(animationId);

        sphere.style.transform = "scale(1)";
      }
    </script>
  </body>
</html>
